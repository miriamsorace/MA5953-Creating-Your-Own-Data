---
title: "Topic Models"
author: "Miriam Sorace"
date: "20/02/2023"
output: html_document
---

```{r, include=FALSE}

#### GLOBAL OPTIONS (REPORT RENDERING)

# include=FALSE means that this particular R code chunk will not be included in the final report. Useful for global settings or bits of code that might not be necessary to show in the final report (settings/set-up lines of code).
if (!("knitr" %in% installed.packages())) {
  install.packages('knitr', repos='http://cran.rstudio.org')}
library(knitr)

if (!("formatR" %in% installed.packages())) {
  install.packages("formatR")}
library(formatR)

knitr::opts_chunk$set(echo = TRUE, error = FALSE, warning = FALSE, message = FALSE, fig.align = "center",
                      tidy.opts=list(width.cutoff=70), tidy=TRUE) #to avoid source code going out of bounds
                                                                  #does not work if single var name is too
                                                                  #long though, as in point 5 below!  

#this line is used to specify any global settings to be applied to the R Markdown script.   The example sets all code chunks as “echo=TRUE”, meaning they will be included in the final rendered version, whereas error/warning messages or any other messages from R will not be displayed in the final, 'knitted' R Markdown file.

### permanently setting the CRAN mirror (avoids error "trying to use CRAN without setting a mirror")

local({r <- getOption("repos")
       r["CRAN"] <- "http://cran.r-project.org"
       options(repos=r)})

```




```{r, include = F}

#### INSTALL RELEVANT PACKAGES

if (!("quanteda" %in% installed.packages())) {
  install.packages("quanteda")
}

#quanteda extensions: 
if (!("quanteda.corpora" %in% installed.packages())) {
  devtools::install_github("quanteda/quanteda.corpora")
}

if (!("quanteda.dictionaries" %in% installed.packages())) {
  devtools::install_github("kbenoit/quanteda.dictionaries")
}

if (!("quanteda.textmodels" %in% installed.packages())) {
   install.packages("quanteda.textmodels")
}


if (!("quanteda.textplots" %in% installed.packages())) {
  install.packages("quanteda.textplots")
}

if (!("quanteda.textstats" %in% installed.packages())) {
  install.packages("quanteda.textstats")
}


if (!("stm" %in% installed.packages())) {
  install.packages("stm")
}




#additional packages

if (!("readtext" %in% installed.packages())) {
  install.packages("readtext")
}

#data manipulation

if (!("dplyr" %in% installed.packages())) {
  install.packages("dplyr")
}

if (!("lubridate" %in% installed.packages())) {
  install.packages("lubridate")
}


library(quanteda)
library(quanteda.corpora)
library(quanteda.dictionaries)
library(quanteda.textmodels)
library(quanteda.textplots)
library(quanteda.textstats)
library(readtext)
library(dplyr)
library(lubridate)
library(stm)



```




```{r, include=F}
##### REMEMBER: WORKING DIRECTORY!

# Either Session --> Set Working Directory --> To Source File Location (should do it automatically, but only when knitting - so, if you want to run the code bit by bit first do set the wd here). To Source File Location means that the data will be imported and saved IN THE SAME FOLDER where you saved the RMarkdown file you're working with!

## OR

## setwd("")

```


## Task 1: Load and Clean the Text Data (usual first step!)

The lines of code below are useful to merge the two twitter datasets and to transform the .csv files into corpus objects, which allow text analysis functions to be applied to the texts. We have seen similar lines of code in previous classes, so this should not be new.

The only **important** difference this week is that instead of merging corpus objects, we'll first merge the two tweet datasets, so that no conflict arise and all meta-data is preserved. We've shown in the previous weeks that quanteda gives the option to merge corpus objects, the below offers an alternative - which works better for some operations that topic model analysis require.

```{r}

ObamaTweets<-readtext("Obama_tweets.csv", text_field = "text", encoding = "ISO-8859-1")
RubioTweets<-readtext("Rubio_tweets.csv", text_field = "text", encoding = "ISO-8859-1")

#generate author variable
ObamaTweets<-ObamaTweets %>%  
   mutate(author = case_when(grepl("Obama", doc_id) ~ "Obama"))

RubioTweets<-RubioTweets %>%  
   mutate(author = case_when(grepl("Rubio", doc_id) ~ "Rubio"))


MasterTweets <- rbind(ObamaTweets, RubioTweets)


#Twitter-specific step: remove emoticons (using regular expression for emojis/non-ASCII characters):
MasterTweets$text <-gsub("[^\x01-\x7F]", "", MasterTweets$text)
MasterCorpus<-corpus(MasterTweets$text, docvars = MasterTweets)

#renaming some variables

MasterCorpus$timestamp<-docvars(MasterCorpus, "created_at")

#Converting and trimming the DFM:

DFM_Master<- tokens(MasterCorpus, 
                   remove_punct = TRUE, 
                   remove_symbols = T, 
                   remove_numbers=T, 
                   remove_url=T) %>%
                   dfm() %>%
                   dfm_tolower()


# remove stopwords:
DFM_Master<- dfm_remove(DFM_Master, pattern = stopwords("en"))

# to remove other words you think irrelevant (stopword lists may not be comprehensive)
DFM_Master <- dfm_remove(DFM_Master, pattern = c("one", "also", "president", "amp", "obama", "rt"))


```

## Task 2: Run the Topic Model

We'll use the Structural Topic Model (STM), which allows to explore topics by specific covariate (in our case, the author of the Tweets - plugged in the "prevalence=" attribute of the stm function). Along the lines of Jack Blumenau's code here: https://github.com/verenakunz/ME414/blob/master/day9/ME414_assignment9_solution.Rmd.

First, we need to convert our dfm to the stm format. Then we apply the stm to the set of documents (which can take 10 minutes, longer the more topics there are). K specifies the number of topics we want to retrieve/we think lead to coherent clusters.

NB: the conversion to stm object may result in a warning message telling us some documents have been dropped. This is likely due to the fact that after trimming, some documents will consist of zero features. If your run this line of code: sum(ntoken(DFM_Master) == 0) it will tell you how many documents in your corpus have zero features after trimming.

```{r}
DFM_stm <- convert(DFM_Master, to = "stm", docvars = docvars(MasterCorpus))

```

```{r}
K <- 15
stm_RESULT <- stm(documents = DFM_stm$documents, 
              vocab = DFM_stm$vocab, 
              data = DFM_stm$meta,
              prevalence = ~author,
              K, seed = 123, verbose = FALSE)
```


## Task 3: Results. Validation & Plots

First, we check out the 15 topics and try to label them by looking at their top words ...

```{r}
plot(stm_RESULT, n=5)
topic_lab <- labelTopics(stm_RESULT)
topic_lab <- apply(topic_lab$prob,1, function(x) paste(x, collapse=";"))
print(topic_lab)
```

and by checking out top documents in each ... e.g. top 5 documents in the healthcare topic (with author information too!
*NB* For your report, you should provide a series of these analyses (not just one), to explore and assess the face validity of your topics. A detailed discussion of this `labelling' step is expected.

```{r}
top_docs <- apply(stm_RESULT$theta, 2, function(x) order(x, decreasing = T)[1:5])

top_health_docs <- top_docs[,grep("health",topic_lab)]

DFM_stm$meta[top_health_docs,c("text", "author")]

```


then we plot differences between our two authors in the discussion of topics:

```{r}
author_effect <- estimateEffect(~author, stm_RESULT, metadata = DFM_stm$meta)

plot.estimateEffect(author_effect, "author", method = "difference", 
                    cov.value1 = "Rubio", cov.value2 = "Obama",
                    verbose.labels=F,
                    title("Mean Difference in Topic Proportions (Rubio-Obama)"),
                    xlab="Left: Obama; Right: Rubio")

                    
```



